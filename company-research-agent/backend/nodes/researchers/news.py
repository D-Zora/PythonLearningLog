from langchain_core.messages import AIMessage
from typing import Dict, Any
from ...classes import ResearchState
from .base import BaseResearcher

class NewsScanner(BaseResearcher):
    def __init__(self, use_local_data: bool = False) -> None:
        # æ¨¡å¼åˆ‡æ¢è¯´æ˜Žï¼š
        # - use_local_data=True: ä½¿ç”¨æœ¬åœ°æ•°æ®æ¨¡å¼ï¼ˆç”¨äºŽæµ‹è¯•ï¼‰
        # - use_local_data=False: ä½¿ç”¨ Tavily API æ¨¡å¼ï¼ˆç”¨äºŽç”Ÿäº§çŽ¯å¢ƒï¼‰
        # æ³¨æ„ï¼šæœ¬åœ°æ•°æ®æ¨¡å¼ä¸‹ï¼Œéœ€è¦åœ¨ local_data/{company_name}/ ç›®å½•ä¸‹æœ‰å¯¹åº”çš„ JSON æ–‡ä»¶
        super().__init__(use_local_data=use_local_data)
        self.analyst_type = "news_analyst"

    async def analyze(self, state: ResearchState) -> Dict[str, Any]:
        company = state.get('company', 'Unknown Company')
        msg = [f"ðŸ“° News Scanner analyzing {company}"]
        
        # ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼ˆæœ¬åœ°æ•°æ®å’Œ API æ¨¡å¼éƒ½ä½¿ç”¨ç›¸åŒçš„æŸ¥è¯¢ç”Ÿæˆé€»è¾‘ï¼‰
        queries = await self.generate_queries(state, """
        Generate queries on the recent news coverage of {company} such as:
        - Recent company announcements
        - Press releases
        - New partnerships
        """)

        # æ·»åŠ æŸ¥è¯¢æ¶ˆæ¯ï¼ˆæœ¬åœ°æ•°æ®å’Œ API æ¨¡å¼éƒ½æ˜¾ç¤ºç›¸åŒçš„æŸ¥è¯¢ä¿¡æ¯ï¼‰
        subqueries_msg = "ðŸ” Subqueries for news analysis:\n" + "\n".join([f"â€¢ {query}" for query in queries])
        messages = state.get('messages', [])
        messages.append(AIMessage(content=subqueries_msg))
        state['messages'] = messages
        
        news_data = {}
        
        # å¤„ç†ç½‘ç«™æŠ“å–æ•°æ®ï¼ˆæœ¬åœ°æ•°æ®å’Œ API æ¨¡å¼éƒ½æ”¯æŒï¼‰
        if site_scrape := state.get('site_scrape'):
            msg.append("\nðŸ“Š Including site scrape data in company analysis...")
            company_url = state.get('company_url', 'company-website')
            news_data[company_url] = {
                'title': state.get('company', 'Unknown Company'),
                'raw_content': site_scrape,
                'query': f'News and announcements about {company}'
            }
        
        # æ‰§è¡Œæœç´¢ï¼ˆæ ¹æ®æ¨¡å¼è‡ªåŠ¨é€‰æ‹©æœ¬åœ°æ•°æ®æˆ– APIï¼‰
        try:
            for query in queries:
                documents = await self.search_documents(state, [query])
                if documents:
                    for url, doc in documents.items():
                        doc['query'] = query
                        news_data[url] = doc
            
            msg.append(f"\nâœ“ Found {len(news_data)} documents")
            if websocket_manager := state.get('websocket_manager'):
                if job_id := state.get('job_id'):
                    await websocket_manager.send_status_update(
                        job_id=job_id,
                        status="processing",
                        message=f"Found {len(news_data)} documents using {'local data' if self.use_local_data else 'Tavily API'}",
                        result={
                            "step": "Searching",
                            "analyst_type": "News Scanner",
                            "queries": queries,
                            "mode": "local_data" if self.use_local_data else "tavily_api"  # æ·»åŠ æ¨¡å¼ä¿¡æ¯
                        }
                    )
        except Exception as e:
            msg.append(f"\nâš ï¸ Error during research: {str(e)}")
        
        # æ›´æ–°çŠ¶æ€ï¼ˆæœ¬åœ°æ•°æ®å’Œ API æ¨¡å¼ä½¿ç”¨ç›¸åŒçš„æ•°æ®ç»“æž„ï¼‰
        messages = state.get('messages', [])
        messages.append(AIMessage(content="\n".join(msg)))
        state['messages'] = messages
        state['news_data'] = news_data
        
        return {
            'message': msg,
            'news_data': news_data
        }

    async def run(self, state: ResearchState) -> Dict[str, Any]:
        return await self.analyze(state) 